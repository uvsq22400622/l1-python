{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"position: absolute;right: 0;\" src=\"data:image/svg+xml,%3Csvg%20height%3D%2295.834%22%20width%3D%2289.004%22%20xml%3Aspace%3D%22preserve%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%3Cpath%20style%3D%22fill%3A%230092bd%3Bfill-opacity%3A1%3Bfill-rule%3Anonzero%3Bstroke%3Anone%3Bstroke-width%3A.721541%22%20d%3D%22m39.987%200%204.506%2056.336L48.986%200ZM0%2041.473c7.22%205.11%2030.7%2021.33%2030.7%2021.33L0%2032.02Zm0-11.61%2032.69%2031.06L0%2016.767ZM29.056%200l12.985%2056.536L38.711%200Zm10.6%2057.1L27.769%200H6.177c-3.4%200-6.17%202.9-6.17%206.475v8.1l34.915%2044.747L6.458%206.202c.354-.212.688-.426%201.038-.637l29.558%2052.46L16.56%201.037c.359-.153.73-.314%201.1-.46zM0%2071.853c.422.088%201.091.171%202.013.171l24.83.066C19.369%2070.775%202.508%2068.863%200%2068.42Zm0-5.447c3.731.656%2027.2%203.62%2027.2%203.62S4.3%2062.468%200%2061.001zm0-15.54c6.295%203.108%2029.304%2014.059%2029.304%2014.059S6.777%2048.527%200%2043.546zm0%208.139c3.968%201.254%2028.244%208.561%2028.244%208.561S6.312%2056.218%200%2052.914zm86.24%2013.332c1.567%200%202.415-.237%202.764-.4V68.42c-2.588.466-19.182%202.52-26.645%203.854zM82.824%200h-21.59L49.692%2056.966%2071.312.573c.006%200%20.012.01.016.015l.008-.015c.37.146.749.312%201.123.463l-20.155%2057.21%2029.174-52.68c.005.013.009.013.017.018l.013-.018c.34.219.68.425%201.04.636l-27.79%2053.337%2034.245-44.987V6.473C89.003%202.897%2086.226%200%2082.824%200m-26.14%2061.16%2032.318-31.326V16.772Zm32.319-19.705V32.02l-30.64%2031.05c1.523-1.081%2023.69-16.692%2030.64-21.615M50.294%200l-3.01%2056.388L60.234%200Zm38.709%2066.406v-5.41c-4.247%201.447-26.813%208.905-27.178%209.026.87-.129%2023.62-2.998%2027.178-3.616m0-15.558v-7.302c-6.614%204.845-28.127%2020.823-29.264%2021.673%201.365-.679%2023.203-11.375%2029.264-14.37m0%208.149v-6.084c-6.209%203.252-27.195%2014.27-27.9%2014.64%201.215-.383%2024.118-7.365%2027.9-8.556%22%2F%3E%3Cpath%20style%3D%22fill%3A%2380ba27%3Bfill-opacity%3A1%3Bfill-rule%3Anonzero%3Bstroke%3Anone%3Bstroke-width%3A.721541%22%20d%3D%22M88.544%2074.062c-.455.13-1.204.249-2.304.249l-41.284.015L.87%2074.192a6.236%206.236%200%200%201-.842-.118v5.553c0%204.546%203.081%206.827%207.855%208.234%200%200%2032.092%207.973%2037.04%207.973%204.968%200%2036.218-7.973%2036.218-7.973%204.121-1.236%207.863-3.688%207.863-8.234v-5.718c-.106.047-.254.1-.46.153%22%2F%3E%3C%2Fsvg%3E\" alt=\"UVSQ Logo\"/>\n",
    "<h1><center>IN202 – Représentation des données</center></h1>\n",
    "<h2><center>TD 7-8 – Compression sans pertes</center></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Compression de Huffman\n",
    "On va commencer par implémenter une compression de Huffman. Ça peut sembler compliqué, mais si on décompose bien les étapes et qu'on les implémente avec des fonctions séparées, ça devient tout à fait faisable.\n",
    "\n",
    "Pour commencer, donnez la table des occurrences du texte qu'on utilisait pour tester notre algorithme. Mais plutôt que de le faire à la main, codez une fonction qui calcule ce tableau. Là, c'est vraiment facile. Quelle structure est adaptée pour associer un nombre d'occurrences à un caractère&nbsp;?\n",
    "\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "Une fois cette structure créée, il ne nous reste plus qu'à la convertir en liste pour pouvoir la trier par occurrences décroissantes (ce qu'un dictionnaire ne peut faire, vu qu'il utilise des clés de type quelconque) et renvoyer cette liste.\n",
    "\n",
    "Implémentez la fonction et affichez le tableau d'occurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tableau_occurrences(texte):\n",
    "    occurrences = #À COMPLÉTER\n",
    "\n",
    "    # On compte le nombre d'occurrences\n",
    "    for car in texte:\n",
    "        if car in occurrences:\n",
    "            #À COMPLÉTER\n",
    "\n",
    "    # On renvoie le dictionnaire trié par ordre décroissant de valeurs\n",
    "    return sorted(occurrences.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "texte = \"Voici le texte à compresser. J'espère qu'il y aura beaucoup de texte qu'on arrivera à compresser.\"\n",
    "\n",
    "resultat = tableau_occurrences(texte)\n",
    "\n",
    "print(\"| Caractère | Occurrences |\")\n",
    "print(\"|-----------|-------------|\")\n",
    "for char, count in resultat:\n",
    "    if char == \" \":\n",
    "        char = \"espace\"\n",
    "    elif char == \"\\n\":\n",
    "        char = \"\\\\n\"\n",
    "    print(f\"| {char:<9} | {count:<11} |\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construisez à la main l'arbre de Huffman. Pour simplifier, ne prenez que la première phrase du texte.\n",
    "\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "Déduisez de cet arbre un codage binaire sans préfixe de chaque lettre.\n",
    "\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "Utilisez ce codage pour donner la représentation binaire de cette phrase. Combien gagne-t-on&nbsp;?\n",
    "\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "Maintenant, on va implémenter ce codage. Dans un premier temps, on va s'attaquer à la construction de l'arbre de Huffman. La première question, c'est&nbsp;: comment implémenter cet arbre&nbsp;?\n",
    "\n",
    "On va utiliser une structure de dictionnaires imbriqués. un noeud est un dictionnaire avec cinq valeurs&nbsp;:\n",
    " * une valeur de clé <code class=\"language-python\"><span class=\"ͼ12\">\"occ\"</span></code>, qui contient la valeur d'occurrence\n",
    " * une valeur de clé <code class=\"language-python\"><span class=\"ͼ12\">\"parent\"</span></code> qui contient le parent de l'arbre\n",
    " * une valeur de clé <code class=\"language-python\"><span class=\"ͼ12\">\"gauche\"</span></code> qui contient le sous-arbre gauche\n",
    " * une valeur de clé <code class=\"language-python\"><span class=\"ͼ12\">\"droit\"</span></code> qui contient le sous-arbre droit\n",
    " * une valeur de clé<code class=\"language-python\"><span class=\"ͼ12\">\"car\"</span></code> qui représente le caractère\n",
    "\n",
    "Évidemment, la clé n'existe dans le dictionnaire que s'il y a lieu. La racine n'aura pas de clé <code class=\"language-python\"><span class=\"ͼ12\">\"parent\"</span></code>, et une feuille n'aura pas de clé <code class=\"language-python\"><span class=\"ͼ12\">\"gauche\"</span></code> ni <code class=\"language-python\"><span class=\"ͼ12\">\"droit\"</span></code>. Vous avez peut-être l'impression que ça va être compliqué à coder, mais c'est en fait assez simple, si on prend les choses dans l'ordre. Écrivez la structure correspondant à cet arbre (à la place de la valeur de <code class=\"language-python\"><span class=\"ͼ12\">\"parent\"</span></code>, mettez juste `...`, sinon ce serait compliqué à décrire)&nbsp;:\n",
    "\n",
    "<img src=\"data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%22215%22%20height%3D%22139%22%20overflow%3D%22hidden%22%20xmlns%3Av%3D%22https%3A%2F%2Fvecta.io%2Fnano%22%3E%3Cstyle%3E%3C!%5BCDATA%5B.B%7Bfont-size%3A24px%7D.C%7Bstroke%3A%2369043b%7D.D%7Bstroke-width%3A1.333%7D.E%7Bstroke-miterlimit%3A8%7D.F%7Bfill%3A%23940654%7D.G%7Bfill-rule%3Aevenodd%7D.H%7Bfont-family%3AArial%2CArial_MSFontService%2Csans-serif%7D.I%7Bfont-family%3AConsolas%2CConsolas_MSFontService%2Csans-serif%7D%5D%5D%3E%3C%2Fstyle%3E%3Cpath%20d%3D%22M49.523%2094.409l34.981-41.847-2.046-1.71-34.981%2041.847zm38.218-37.404L91.178%2042.5l-13.666%205.954z%22%20fill%3D%22%2369043b%22%2F%3E%3Cpath%20d%3D%22M8.5%20110c0-12.979%2010.521-23.5%2023.5-23.5S55.5%2097.021%2055.5%20110%2044.979%20133.5%2032%20133.5%208.5%20122.979%208.5%20110z%22%20class%3D%22C%20D%20E%20F%20G%22%2F%3E%3Ctext%20fill%3D%22%23fff%22%20transform%3D%22translate(14.797%20118)%22%20class%3D%22B%20I%22%3Ec%3C%2Ftext%3E%3Ctext%20fill%3D%22%23fff%22%20transform%3D%22translate(27.964%20118)%22%20class%3D%22B%20H%22%3E%2C1%3C%2Ftext%3E%3Cpath%20d%3D%22M160.5%20110c0-12.979%2010.521-23.5%2023.5-23.5s23.5%2010.521%2023.5%2023.5-10.521%2023.5-23.5%2023.5-23.5-10.521-23.5-23.5z%22%20class%3D%22C%20D%20E%20F%20G%22%2F%3E%3Ctext%20fill%3D%22%23fff%22%20transform%3D%22translate(166.621%20118)%22%20class%3D%22B%20I%22%3Ed%3C%2Ftext%3E%3Ctext%20fill%3D%22%23fff%22%20transform%3D%22translate(179.787%20118)%22%20class%3D%22B%20H%22%3E%2C1%3C%2Ftext%3E%3Cpath%20d%3D%22M84.5%2025c0-12.979%2010.521-23.5%2023.5-23.5s23.5%2010.521%2023.5%2023.5-10.521%2023.5-23.5%2023.5S84.5%2037.979%2084.5%2025z%22%20class%3D%22C%20D%20E%20F%20G%22%2F%3E%3Ctext%20fill%3D%22%23fff%22%20transform%3D%22translate(100.626%2034)%22%20class%3D%22B%20H%22%3E2%3C%2Ftext%3E%3Cpath%20d%3D%22M166.155%2094.409l-34.982-41.847%202.046-1.71%2034.982%2041.847zm-38.218-37.403L124.5%2042.5l13.666%205.954z%22%20fill%3D%22%2369043b%22%2F%3E%3C%2Fsvg%3E\">\n",
    "\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "Évidemment, le but n'est pas de le construire à la main... Quelle est l'opération principale qu'on applique itérativement pour construire l'arbre de Huffman&nbsp;?\n",
    "\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "Rien de difficile en Python. Implémentez cette fonction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion(a1, a2):\n",
    "    racine = {\n",
    "        #À COMPLÉTER\n",
    "    }\n",
    "\n",
    "    a1[ #À COMPLÉTER\n",
    "    a2[ #À COMPLÉTER\n",
    "    \n",
    "    return racine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, utilisez cette fonction pour recréer l'exemple précédent en créant deux feuilles, et en générant l'arbre à partir de ces deux feuilles. Attention à l'ordre dans lequel vous passez les feuilles, souvenez-vous que l'ordre des enfants dans un arbre de Huffman est important&nbsp;!\n",
    "Par contre, comme l'affichage avec `print` va devenir un peu difficile à lire, on va utiliser le package `pprint`(_pretty print_)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pp\n",
    "\n",
    "f1 = {\n",
    "    \"car\": \"c\",\n",
    "    \"occ\": 1\n",
    "}\n",
    "\n",
    "f2 = {\n",
    "    \"car\": \"d\",\n",
    "    \"occ\": 1\n",
    "}\n",
    "\n",
    "f3 = {\n",
    "    \"car\": \"b\",\n",
    "    \"occ\": 2\n",
    "}\n",
    "\n",
    "a1 = fusion(f1, f2)\n",
    "a2 = fusion(a1, f3)\n",
    "pp(a2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous noterez que le lien vers le parent n'est pas suivi (heureusement, vu que c'est une référence circulaire, on ne serait pas rendus...).\n",
    "\n",
    "Maintenant, on va créer une _forêt_ d'arbres qui ne contiennent que des feuilles, correspondant aux feuilles du texte. Il faut donc parcourir le tableau d'occurrences, et créer pour chaque couple caractère/occurrences une feuille qu'on ajoutera dans la forêt. Vu qu'il faudra ensuite trier cette forêt, une liste fera l'affaire. La bonne nouvelle, c'est que comme le tableau des occurrences est déjà trié, on n'a pas besoin de le refaire sur cette forêt ! Enfin, pas pour l'instant..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def foret_huffman(texte):\n",
    "    foret = []\n",
    "\n",
    "    for car, occ in tableau_occurrences(texte):\n",
    "        #À COMPLÉTER\n",
    "\n",
    "    return foret\n",
    "\n",
    "texte = \"Voici le texte à compresser. J'espère qu'il y aura beaucoup de texte qu'on arrivera à compresser.\"\n",
    "pp(foret_huffman(texte))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, il ne nous reste plus qu'à itérer tant que la forêt n'est pas vide, pour fusionner les deux arbres de plus petite occurrence. Là, par contre, une fois que les deux arbres auront été remplacés par l'arbre fusionné, il faudra retrier la liste. Inspirez-vous de l'instruction utilisée dans `tableau_occurrences` (et regardez la doc de cette instruction si vous avez un doute...)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arbre_huffman(texte):\n",
    "    foret = foret_huffman(texte)\n",
    "    \n",
    "    while #À COMPLÉTER\n",
    "    \n",
    "    return foret[0]\n",
    "\n",
    "arbre = arbre_huffman(texte)\n",
    "pp(arbre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a presque fini, il ne reste plus qu'à récupérer une chaine de caractères représentant le code binaire d'un caractère. Commençons par implémenter une fonction qui renvoie la feuille correspondant à un caractère dans l'arbre de Huffman. Là, c'est un peu subtil. Mais on va exploiter le fait qu'un arbre est une structure _récursive_. Après tout, un sous-arbre, c'est un arbre aussi. Donc si la donnée qu'on cherche n'est pas dans la racine, on n'a qu'à relancer cette recherche dans les sous-arbres de cette racine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feuille_huffman(arbre, caractere):\n",
    "    if arbre.get(\"car\", None) == caractere:\n",
    "        #À COMPLÉTER\n",
    "    else:\n",
    "        #À COMPLÉTER\n",
    "    # Si on n'a trouvé la valeur ni dans le sommet courant,\n",
    "    # ni dans ses sous-arbres\n",
    "    return None\n",
    "\n",
    "print(feuille_huffman(arbre, \"a\"))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'affichage a l'air un peu long, mais c'est juste à cause du lien vers le parent. Du moment que les champs \n",
    "<code class=\"language-python\"><span class=\"ͼ12\">\"occ\"</span></code> et \n",
    "<code class=\"language-python\"><span class=\"ͼ12\">\"car\"</span></code> sont bien là, tout va bien.\n",
    "\n",
    "La prochaine étape est d'implémenter la construction de la _table de conversion_&nbsp;: une structure qui associe un caractère à un code binaire construit en remontant depuis la feuille de ce caractère jusqu'à la racine. Là, il manque une information à notre arbre de Huffman. Laquelle&nbsp;? Comment la représenter&nbsp;?\n",
    "\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "On pourrait ajouter cette information pendant la construction de l'arbre, mais ça serait en fait assez compliqué, c'est nettement plus simple d'ajouter cette information après. Créez une fonction qui prend en paramètre un arbre de Huffman, et qui ajoute l'information sur l'arbre créé. Un indice&nbsp;: l'ajout de l'information se fait assez facilement de manière récursive, vous pouvez donc créer une fonction récursive, et lui passer l'arbre de Huffman (comme pour la recherche d'une feuille).\n",
    "\n",
    "Par contre, on va essayer de gagner un peu de temps&nbsp;: plutôt que d'insérer dans un sommet uniquement le code du lien vers son parent, on va directement y ajouter en plus le code du parent. Comme ça, les codes intermédiaires vont se propager jusqu'aux feuilles, qui auront directement le code complet du caractère. Ça nous évitera de refaire un parcours pour construire le code d'un caractère. Par contre, on devra stocker le code intermédiaire dans les sommets internes. Concrètement, on sacrifie de la place pour gagner du temps. En gros, un arbre ressemblera à ça&nbsp;:\n",
    "\n",
    "<img src=\"data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%221785%22%20height%3D%22649%22%20overflow%3D%22hidden%22%20xmlns%3Av%3D%22https%3A%2F%2Fvecta.io%2Fnano%22%3E%3Cstyle%3E%3C!%5BCDATA%5B.B%7Bfill%3A%23fff%7D.C%7Bfont-family%3ACambria%20Math%2CCambria%20Math_MSFontService%2Csans-serif%7D.D%7Bfont-size%3A24px%7D.E%7Bstroke-miterlimit%3A8%7D.F%7Bstroke%3A%2369043b%7D.G%7Bstroke-width%3A1.333%7D.H%7Bfill%3A%23940654%7D.I%7Bfill-rule%3Aevenodd%7D.J%7Bfont-family%3AConsolas%2CConsolas_MSFontService%2Csans-serif%7D.K%7Bfont-size%3A32px%7D.L%7Bfont-size%3A29px%7D.M%7Bstroke-width%3A2.667%7D.N%7Bfont-size%3A27px%7D%5D%5D%3E%3C%2Fstyle%3E%3Cg%20class%3D%22F%20E%22%3E%3Cg%20fill%3D%22none%22%20class%3D%22M%22%3E%3Cpath%20d%3D%22M1645.108%20499.131L1549.5%20387.5m-401.114%20115.754L1098.5%20389.5m-46%20113.882l44.454-114.881m-236.454-.092L980.333%20268.5%22%2F%3E%3Cpath%20d%3D%22M1098.034%20389.345L978.5%20269.5M672.441%20503.254L623.5%20389.5m-46%20113.754L622.957%20389.5M499.222%20270.842L253.5%20139.5%22%2F%3E%3Cpath%20d%3D%22M377.5%20388.409L499.042%20268.5m124.699%20120.845L500.5%20269.5m-247-128l476.319-109m478.276%20111.688L731.5%2032.5m698.173%20236.903L1208.5%20143.5%22%2F%3E%3Cpath%20d%3D%22M980.5%20271.095L1208.681%20143.5M1405.5%20617.254l47.729-113.754M1596.5%20617.377l47.364-115.877m-143%20115.877L1453.5%20501.5m238.823%20115l-48.823-118m-190%20.631l94.729-111.631m-188.365%20113.631L1312.5%20389.5m0-3.653L1429.212%20267.5M1263.5%20501.102l48.276-115.602%22%2F%3E%3C%2Fg%3E%3Cuse%20href%3D%22%23B%22%20class%3D%22G%20H%20I%22%2F%3E%3C%2Fg%3E%3Ctext%20transform%3D%22translate(1676.059%20625)%22%20class%3D%22B%20C%20D%22%3EV%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1688.099%20625)%22%20class%3D%22B%20C%20D%22%3E%2C%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1693.099%20625)%22%20class%3D%22B%20C%20D%22%3E1%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-287%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1392.456%20625)%22%20class%3D%22B%20C%20D%22%3El%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1398.956%20625)%22%20class%3D%22B%20C%20D%22%3E%2C%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1403.956%20625)%22%20class%3D%22B%20C%20D%22%3E1%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-96%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1580.788%20625)%22%20class%3D%22B%20C%20D%22%3Ex%2C1%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-191%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1485.33%20625)%22%20class%3D%22B%20C%20D%22%3E%C3%A0%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1496.997%20625)%22%20class%3D%22B%20C%20D%22%3E%2C%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1501.997%20625)%22%20class%3D%22B%20C%20D%22%3E1%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-239%22%20y%3D%22-118%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1445.935%20507)%22%20class%3D%22B%20C%20D%22%3E2%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-48%22%20y%3D%22-118%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1636.85%20507)%22%20class%3D%22B%20C%20D%22%3E2%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-428%22%20y%3D%22-118%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1250.546%20507)%22%20class%3D%22B%20C%20D%22%3Er%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1258.2%20507)%22%20class%3D%22B%20C%20D%22%3E%2C%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1263.2%20507)%22%20class%3D%22B%20C%20D%22%3E2%3C%2Ftext%3E%3Cuse%20href%3D%22%23C%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1344.664%20507)%22%20class%3D%22B%20C%20D%22%3Es%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1354.997%20507)%22%20class%3D%22B%20C%20D%22%3E%2C%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1359.997%20507)%22%20class%3D%22B%20C%20D%22%3E2%3C%2Ftext%3E%3Cuse%20href%3D%22%23D%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1304.602%20394)%22%20class%3D%22B%20C%20D%22%3E4%3C%2Ftext%3E%3Cuse%20href%3D%22%23D%22%20x%3D%22-104%22%20y%3D%22-243%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1194.449%20151)%22%20class%3D%22B%20C%20D%22%3E16%3C%2Ftext%3E%3Cg%20class%3D%22F%20E%22%3E%3Cpath%20d%3D%22M910.183%20503.411L862.5%20392.5m-50%20110.882l48.093-114.881%22%20fill%3D%22none%22%20class%3D%22M%22%2F%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-594%22%20y%3D%22-229%22%20class%3D%22G%20H%20I%22%2F%3E%3C%2Fg%3E%3Ctext%20transform%3D%22translate(1090.662%20396)%22%20class%3D%22B%20C%20D%22%3E4%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-879%22%20y%3D%22-115%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(797.309%20510)%22%20class%3D%22B%20C%20D%22%3Eo%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(809.976%20510)%22%20class%3D%22B%20C%20D%22%3E%2C%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(814.976%20510)%22%20class%3D%22B%20C%20D%22%3E2%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-783%22%20y%3D%22-115%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(895.767%20510)%22%20class%3D%22B%20C%20D%22%3Ei%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(902.433%20510)%22%20class%3D%22B%20C%20D%22%3E%2C%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(907.433%20510)%22%20class%3D%22B%20C%20D%22%3E2%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-831%22%20y%3D%22-229%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(853.871%20396)%22%20class%3D%22B%20C%20D%22%3E4%3C%2Ftext%3E%3Cuse%20href%3D%22%23C%22%20x%3D%22-380%22%20y%3D%22-230%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(972.267%20277)%22%20class%3D%22B%20C%20D%22%3E8%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-639%22%20y%3D%22-115%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1038.403%20510)%22%20class%3D%22B%20C%20D%22%3Ec%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1048.903%20510)%22%20class%3D%22B%20C%20D%22%3E%2C%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1053.903%20510)%22%20class%3D%22B%20C%20D%22%3E2%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-543%22%20y%3D%22-115%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1134.85%20510)%22%20class%3D%22B%20C%20D%22%3Et%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1143.37%20510)%22%20class%3D%22B%20C%20D%22%3E%2C%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1148.37%20510)%22%20class%3D%22B%20C%20D%22%3E2%3C%2Ftext%3E%3Cg%20class%3D%22E%20F%22%3E%3Cpath%20d%3D%22M1548.425%20387.074L1427.5%20263.5%22%20fill%3D%22none%22%20class%3D%22M%22%2F%3E%3Cuse%20href%3D%22%23D%22%20x%3D%22-581%22%20y%3D%22-353%22%20class%3D%22G%20H%20I%22%2F%3E%3C%2Fg%3E%3Ctext%20transform%3D%22translate(716.933%2041)%22%20class%3D%22B%20C%20D%22%3E27%3C%2Ftext%3E%3Cuse%20href%3D%22%23C%22%20x%3D%22-737%22%20y%3D%22-110%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(615.414%20397)%22%20class%3D%22B%20C%20D%22%3E2%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-1315%22%20y%3D%22-228%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(362.906%20397)%22%20class%3D%22B%20C%20D%22%3E_%2C4%3C%2Ftext%3E%3Cuse%20href%3D%22%23C%22%20x%3D%22-860%22%20y%3D%22-229%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(492.218%20278)%22%20class%3D%22B%20C%20D%22%3E6%3C%2Ftext%3E%3Cuse%20href%3D%22%23D%22%20x%3D%22-734%22%20y%3D%22117%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(558.404%20511)%22%20class%3D%22B%20C%20D%22%3Em%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(578.404%20511)%22%20class%3D%22B%20C%20D%22%3E%2C%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(583.404%20511)%22%20class%3D%22B%20C%20D%22%3E1%3C%2Ftext%3E%3Cuse%20href%3D%22%23E%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(657.195%20511)%22%20class%3D%22B%20C%20D%22%3Ep%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(670.529%20511)%22%20class%3D%22B%20C%20D%22%3E%2C%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(675.529%20511)%22%20class%3D%22B%20C%20D%22%3E1%3C%2Ftext%3E%3Cg%20class%3D%22E%20F%22%3E%3Cpath%20d%3D%22M31.5%20270.282L253.815%20139.5%22%20fill%3D%22none%22%20class%3D%22M%22%2F%3E%3Cpath%20d%3D%22M1.5%20268c0-16.845%2013.655-30.5%2030.5-30.5s30.5%2013.655%2030.5%2030.5-13.655%2030.5-30.5%2030.5S1.5%20284.845%201.5%20268z%22%20class%3D%22G%20H%20I%22%2F%3E%3C%2Fg%3E%3Ctext%20transform%3D%22translate(16.594%20276)%22%20class%3D%22B%20C%20D%22%3Ee%2C5%3C%2Ftext%3E%3Cuse%20href%3D%22%23E%22%20x%3D%22875%22%20y%3D%22-117%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1541.393%20394)%22%20class%3D%22B%20C%20D%22%3E4%3C%2Ftext%3E%3Cuse%20href%3D%22%23D%22%20x%3D%22118%22%20y%3D%22-119%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(1422.997%20275)%22%20class%3D%22B%20C%20D%22%3E8%3C%2Ftext%3E%3Cuse%20href%3D%22%23B%22%20x%3D%22-1439%22%20y%3D%22-478%22%20class%3D%22E%20F%20G%20H%20I%22%2F%3E%3Ctext%20transform%3D%22translate(239.417%20147)%22%20class%3D%22B%20C%20D%22%3E11%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(491.029%2067)%22%20class%3D%22J%20K%22%3E0%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(71.816%20204)%22%20class%3D%22J%20K%22%3E00%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(380.355%20194)%22%20class%3D%22J%20K%22%3E01%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(373.106%20323)%22%20class%3D%22J%20K%22%3E010%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(566.038%20317)%22%20class%3D%22J%20K%22%3E011%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(504.33%20444)%22%20class%3D%22J%20L%22%3E0110%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(647.618%20438)%22%20class%3D%22J%20L%22%3E0111%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(958.725%2070)%22%20class%3D%22J%20K%22%3E1%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1050.456%20187)%22%20class%3D%22J%20K%22%3E10%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(864.415%20315)%22%20class%3D%22J%20K%22%3E100%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(767.543%20440)%22%20class%3D%22J%20L%22%3E1000%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(891.764%20440)%22%20class%3D%22J%20L%22%3E1001%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1025.668%20311)%22%20class%3D%22J%20K%22%3E101%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1003.858%20439)%22%20class%3D%22J%20L%22%3E1010%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1126.763%20432)%22%20class%3D%22J%20L%22%3E1011%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1309.113%20180)%22%20class%3D%22J%20K%22%3E11%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1326.443%20309)%22%20class%3D%22J%20K%22%3E110%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1214.531%20456)%22%20class%3D%22J%20L%22%3E1100%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1341.094%20451)%22%20class%3D%22J%20L%22%3E1101%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1538.535%20564)%22%20class%3D%22J%20N%22%3E11110%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1445.946%20424)%22%20class%3D%22J%20L%22%3E1110%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1488.741%20303)%22%20class%3D%22J%20K%22%3E111%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1347.915%20560)%22%20class%3D%22J%20N%22%3E11100%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1471.482%20541)%22%20class%3D%22J%20N%22%3E11101%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1678.822%20567)%22%20class%3D%22J%20N%22%3E11111%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1598.411%20427)%22%20class%3D%22J%20L%22%3E1111%3C%2Ftext%3E%3Cdefs%20%3E%3Cpath%20id%3D%22B%22%20d%3D%22M1661.5%20617c0-16.845%2013.655-30.5%2030.5-30.5s30.5%2013.655%2030.5%2030.5-13.655%2030.5-30.5%2030.5-30.5-13.655-30.5-30.5z%22%2F%3E%3Cpath%20id%3D%22C%22%20d%3D%22M1328.5%20499c0-16.845%2013.879-30.5%2031-30.5s31%2013.655%2031%2030.5-13.879%2030.5-31%2030.5-31-13.655-31-30.5z%22%2F%3E%3Cpath%20id%3D%22D%22%20d%3D%22M1281.5%20385.5c0-17.121%2013.655-31%2030.5-31s30.5%2013.879%2030.5%2031-13.655%2031-30.5%2031-30.5-13.879-30.5-31z%22%2F%3E%3Cpath%20id%3D%22E%22%20d%3D%22M642.5%20502.5c0-17.121%2013.879-31%2031-31s31%2013.879%2031%2031-13.879%2031-31%2031-31-13.879-31-31z%22%2F%3E%3C%2Fdefs%3E%3C%2Fsvg%3E\">\n",
    "\n",
    "Notez que, dans cet exemple, le code d'un enfant gauche est le code du parent préfixé d'un `0`, et le code d'un enfant droit est le code du parent préfixé d'un `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def etiqueter_arbre_huffman(arbre):\n",
    "    if \"parent\" not in arbre:\n",
    "        arbre[\"code\"] = \"\"\n",
    "\n",
    "    if \"gauche\" in arbre:\n",
    "        #À COMPLÉTER\n",
    "        \n",
    "    if \"droit\" in arbre:\n",
    "        #À COMPLÉTER\n",
    "\n",
    "etiqueter_arbre_huffman(arbre)\n",
    "pp(arbre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tout marche bien, réécrivez la fonction <code class=\"language-python\"><span class=\"ͼv\">arbre_huffman</span></code> pour qu'elle effectue l'étiquetage après avoir créé l'arbre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arbre_huffman(texte):\n",
    "    foret = foret_huffman(texte)\n",
    "    \n",
    "    while #À COMPLÉTER\n",
    "    \n",
    "    return arbre\n",
    "\n",
    "arbre = arbre_huffman(texte)\n",
    "pp(arbre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, il faut une fonction qui donne le code binaire d'une lettre. Ce code binaire est celui stocké dans la feuille correspondant au caractère. Mais ce code est une chaine de caractères contenant des <code class=\"language-python\"><span class=\"ͼ12\">\"0\"</span></code> et des <code class=\"language-python\"><span class=\"ͼ12\">\"1\"</span></code>, or il nous faut la vraie valeur binaire. Pour convertir ce texte en valeur binaire,  on va utiliser le type `bitarray`, qui est un tableau de bits individuels. Et cette structure est très pratique, on peut y accéder comme n'importe quel conteneur, par indexation ou par slicing. Vérifiez tout d'abord si vous avez besoin d'installer la bibliothèque&nbsp;:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bitarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour créer une variable de ce type, la fonction <code class=\"language-python\"><span class=\"ͼv\">bitarray</span></code> prend en paramètre une chaine de caractères décrivant une valeur binaire, et génère cette valeur binaire (de type `bitarray`, donc). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitarray import bitarray\n",
    "\n",
    "def code_huffman(arbre, caractere):\n",
    "    if feuille_huffman(arbre, caractere) is None:\n",
    "        print(\"None\", caractere)\n",
    "        return\n",
    "    #À COMPLÉTER\n",
    "\n",
    "print(code_huffman(arbre, \"d\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parfait, on a quasiment fini, il reste juste à réunir tout ce qu'on a fait. Écrivez une fonction qui prend en paramètre un texte à compresser, crée et étiquette l'arbre correspondant, puis parcourt tout le texte pour remplacer chaque caractère par son code de Huffman&nbsp;! Évidemment, il faudra renvoyer l'arbre en plus du texte compressé, si on veut pouvoir le décompresser. Pour créer et mettre à jour un code binaire complet, il suffit de créer un bitarray vide, et lui ajouter des données exactement comme dans n'importe quel conteneur&nbsp;:\n",
    " * avec <code class=\"language-python\"><span class=\"ͼv\">append</span></code> pour ajouter un seul bit (0 ou 1), passé sous forme d'entier\n",
    " * avec <code class=\"language-python\"><span class=\"ͼv\">extend</span></code> pour ajouter plusieurs bits d'un coup (ce qui permet de concaténer deux conteneurs). Dans ce cas, les données soit passés sous la forme d'une chaine de caractères mises en forme. Par exemple, pour passer le code binaire de la variable `valeur`, codée avec `nb` bits, il faut passer à <code class=\"language-python\"><span class=\"ͼv\">extend</span></code> la chaine <code class=\"language-python\"><span class=\"ͼ13\">f\"</span><span class=\"ͼ14\">{</span>valeur:<span class=\"ͼs\">nb</span><span class=\"ͼ14\">}</span><span class=\"ͼ13\">\"</span></code>).\n",
    "À vous de sélectionner la bonne fonction.\n",
    "\n",
    "Testez le tout sur le texte du cours (<code class=\"language-python\"><span class=\"ͼ12\">\"abracadabra\"</span></code>), pour voir si vous retrouvez le même code.\n",
    "<em>À COMPLÉTER</em>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compresse_huffman(texte):\n",
    "    #À COMPLÉTER\n",
    "\n",
    "    # Il faut retourner l'arbre en plus du texte compressé\n",
    "     # pour pouvoir le décompresser\n",
    "    return texte_compresse, arbre\n",
    "\n",
    "texte_a_compresser = \"Voici le texte à compresser. J'espère qu'il y aura beaucoup de texte qu'on arrivera à compresser.\"\n",
    "# texte_a_compresser = \"abracadabra\"\n",
    "texte_compresse, arbre = compresse_huffman(texte_a_compresser)\n",
    "\n",
    "print(texte_compresse)\n",
    "print(f\"taille compressée : {len(texte_compresse)} bits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, ressayez sur la phrase du début de l'exercice. On gagne un espace non négligeable. Mais est-ce vraiment sûr&nbsp;?\n",
    "\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "Utilisez le code ci-dessous pour nuancer l'analyse.\n",
    "<em>À COMPLÉTER</em>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from collections import deque\n",
    "\n",
    "def taille_arbre(tree):\n",
    "    \"\"\"Calcule la taille en octets d'un arbre binaire représenté par des dictionnaires imbriqués\"\"\"\n",
    "    taille = 0\n",
    "    pile = deque([(arbre, 0)])  # (node, depth)\n",
    "\n",
    "    while pile:\n",
    "        sommet, prof = pile.pop()\n",
    "        \n",
    "        # Taille du dictionnaire lui-même\n",
    "        taille += sys.getsizeof(sommet) // 8\n",
    "        \n",
    "        # Champ \"occ\" (int)\n",
    "        occ = sommet[\"occ\"]\n",
    "        if occ == 0:\n",
    "            taille += 8   # 0 nécessite au moins 1 octet\n",
    "        else:\n",
    "            taille += occ.bit_length()\n",
    "        \n",
    "        # Code binaire\n",
    "        taille += len(sommet[\"code\"])\n",
    "        \n",
    "        # Champ \"car\" (str de 1 caractère) ou champs \"gauche\" et \"droit\"\n",
    "        if \"car\" in sommet:\n",
    "            taille += 8  # 1 octet pour un caractère ASCII\n",
    "        else:\n",
    "            # Ajouter les enfants à la pile\n",
    "            pile.append((sommet['gauche'], prof + 1))\n",
    "            pile.append((sommet['droit'], prof + 1))\n",
    "        \n",
    "    return taille\n",
    "\n",
    "def taille_feuilles(arbre):\n",
    "    \"\"\"Calcule la taille en octets des feuilles d'un arbre binaire\"\"\"\n",
    "    taille = 0\n",
    "    pile = deque([arbre])\n",
    "    nb_feuilles = 0\n",
    "\n",
    "    while pile:\n",
    "        sommet = pile.pop()\n",
    "        \n",
    "        if \"car\" in sommet:  # C'est une feuille\n",
    "            # 1 octet pour le caractère, 4 pour le nombre d'occurrences\n",
    "            taille += 5                  \n",
    "        else:\n",
    "            # Si ce n'est pas une feuille, on continue à explorer\n",
    "            pile.append(sommet[\"gauche\"])\n",
    "            pile.append(sommet[\"droit\"])\n",
    "        \n",
    "    return taille\n",
    "\n",
    "print(f\"{taille_arbre(arbre)} octets\")\n",
    "print(f\"{taille_feuilles(arbre)} octets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, maintenant qu'on sait compresser, il faut décompresser. Ça, c'est beaucoup plus simple, il suffit de parcourir le `bitarray` bit par bit, descendre l'arbre en prenant à chaque fois la bonne direction en fonction de la suite de bit, jusqu'à arriver à une feuille, récupérer le caractère correspondant, et continuer jusqu'à arriver au bout du code binaire. Comme souvent, faites attention à la mise à jour de votre indice..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompresse_huffman(arbre, texte_compresse):\n",
    "    texte = \"\"\n",
    "\n",
    "    i = 0\n",
    "    while i < len(texte_compresse):\n",
    "        sommet = arbre\n",
    "        #À COMPLÉTER\n",
    "    return texte\n",
    "\n",
    "print(decompresse_huffman(arbre, texte_compresse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, si tout marche, on peut comparer le gain de place avec la compression algorithmique "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compression algorithmique\n",
    "\n",
    "On va construire un autre compresseur, utilisant une version simplifiée de LZSS. Cet algorithme est une variante de LZ77/LZ78, dans laquelle on n'utilise la représentation par motif que quand on en a besoin. Cette optimisation a été imaginée par Storer et Szymanski, d'où le nom de cette version. C'est d'ailleurs un algorithme encore beaucoup utilisé (dans l'utilitaire gzip, dans le système de fichiers NTFS...).\n",
    "\n",
    "Dans notre version, quand un caractère est seul, on le représente explicitement. On va donc stocker la version compressée du texte dans une liste. Chaque entrée de la liste est&nbsp;:\n",
    " * pour une référence à une séquence répétée : un tuple (distance, longueur). La distance est celle entre l'index où on lit et celui où on recopie ce qu'on lit. La longueur est le nombre de caractères qu'on recopie. On va appeler cette donnée un _match_.\n",
    " * pour un caractère isolé (symbole non répété) : un str contenant ce caractère, qu'on appelera un _littéral_.\n",
    "\n",
    "La vraie version de LZSS stocke un match de forme `(décalage, longueur, caractère suivant)`, mais on va simplifier (au prix d'un taux moyen de compression moindre).\n",
    "\n",
    "D'abord, un peu d'échauffement&nbsp;:\n",
    "1. Donnez le résultat de la compression de `aaaaaaaaaaaaaaaaa`.\n",
    "<em>À COMPLÉTER</em>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_size(mot, i, j):\n",
    "    \"\"\"\n",
    "    Renvoie la valeur du plus grand sous-mot commun,\n",
    "    dans le mot aux positions position i et j avec j < i\n",
    "    \"\"\"\n",
    "    k = 0\n",
    "    while (\n",
    "        #À COMPLÉTER\n",
    "        and\n",
    "        #À COMPLÉTER\n",
    "        and\n",
    "        #À COMPLÉTER\n",
    "    ):\n",
    "        #À COMPLÉTER\n",
    "        \n",
    "    return k\n",
    "    \n",
    "texte_a_compresser = \"Voici le texte à compresser. J'espère qu'il y aura beaucoup de texte qu'on arrivera à compresser.\"\n",
    "print(match_size(texte_a_compresser, 63, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on va utiliser cette fonction <code class=\"language-python\"><span class=\"ͼv\">match_size</span></code> pour chercher des répétitions dans les données déjà traitées.\n",
    "\n",
    "Ce qui nous intéresse, c'est donc le plus long match depuis la position courante, en regardant en arrière. La fonction part donc du début, et appelle à chaque fois <code class=\"language-python\"><span class=\"ͼv\">match_size</span></code> pour vérifier la taille du plus grand match entre la position de départ et la position courante. Et on avance comme ça jusqu'à atteindre la position de départ. À la fin, on renvoie un tuple `(position, taille)` indiquant le plus grand match trouvé.\n",
    "\n",
    "Dans notre exemple, ça devrait être le match ` texte ` en position 8, de taille 7 (avec les espaces avant et après), qu'on trouve en cherchant depuis la position 62. Si on ne trouve aucun match, on renvoie `(0,0)` (mais c'est surtout le 0 de taille qui indique qu'on n'a rien trouvé)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_match(mot, i):\n",
    "    \"\"\"\n",
    "    Renvoie le tuple (position, taille) du plus grand match\n",
    "    trouvé dans mot à partir de la position i\n",
    "    \"\"\"\n",
    "    max_match = 0\n",
    "    max_match_pos = 0\n",
    "    \n",
    "    # On explore toutes les positions antérieures à i\n",
    "    for  #À COMPLÉTER\n",
    "            \n",
    "    return (max_match_pos, max_match)\n",
    "\n",
    "depart = 62\n",
    "pos, taille = max_match(texte_a_compresser, depart)\n",
    "print(pos, taille)\n",
    "print(f\"match maximal : \\\"{texte_a_compresser[pos:pos+taille]}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Par contre, dans les vraies implémentations, on ne cherche pas depuis le début, c'est trop lourd si le texte à coder est long. On utilise une fenêtre glissante. Ça sonne compliqué, mais ça veut juste dire que si on est à une position `i`, on ne cherche pas le match depuis le début, mais uniquement les `n` caractères précédents. D'où le terme _glissante_, puisque quand on passe au carcactère suivant, la fenêtre dans laquelle on cherche se décale&nbsp;!\n",
    "\n",
    "Essayez d'adapter le code pour ajouter cette fenêtre glissante, il n'y a pas grand chose à changer (attention tout de même, si votre fenêtre glissante fait 10, tant qu'on n'est pas à la 11ème case, il faut veiller à ne pas repartir trop en arrière)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_match(mot, i, taille_fenetre):\n",
    "    \"\"\"\n",
    "    Renvoie le tuple (position,taille) du plus grand match\n",
    "    trouvé dans mot à partir de la position i\n",
    "    \"\"\"\n",
    "    #À COMPLÉTER\n",
    "        \n",
    "    return (max_match_pos, max_match)\n",
    "\n",
    "def max_match(mot, i, taille_fenetre):\n",
    "    debut = max(0, i - taille_fenetre)\n",
    "    max_match = 0\n",
    "    max_match_pos = debut  # Correction 1 : initialisation à debut\n",
    "\n",
    "    for j in range(debut, i):\n",
    "        size = match_size(mot, i, j)\n",
    "        if size > max_match:\n",
    "            max_match = size\n",
    "            max_match_pos = j\n",
    "\n",
    "    return (max_match_pos, max_match)\n",
    "\n",
    "\n",
    "depart = 62\n",
    "pos, taille = max_match(texte_a_compresser, depart, 55)\n",
    "print(f\"fenêtre 55, match maximal : \\\"{texte_a_compresser[pos:pos+taille]}\\\"\")\n",
    "pos, taille = max_match(texte_a_compresser, depart, 50)\n",
    "print(f\"fenêtre 50, match maximal : \\\"{texte_a_compresser[pos:pos+taille]}\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant, on est prêts à implémenter la compression. Ce n'est pas bien compliqué avec notre fonction de recherche de matching de taille maximale. Il faut juste parcourir le texte depuis le début, chercher un match, et s'il y en a un (souvenez-vous, <code class=\"language-python\"><span class=\"ͼv\">max_match</span></code> utilise une valeur spécifique pour dire que non), l'utiliser.\n",
    "\n",
    "Attention tout de même&nbsp;: si vous avez trouvé un match, ça veut dire que ce n'est pas juste le caractère courant que vous compressez, mais aussi tous les suivants qui font partie du match. Pensez-y du point de vue de la mise à jour de votre indice de parcours..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compresse_LZ(texte_a_compresser, taille_fenetre):\n",
    "    texte_compresse = []\n",
    "    \n",
    "    # On parcourt chaque lettre du texte\n",
    "    i = 0\n",
    "    #À COMPLÉTER\n",
    "    \n",
    "    return texte_compresse\n",
    "    \n",
    "texte_compresse = compresse_LZ(texte_a_compresser, 100)\n",
    "print(texte_compresse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, ça semble marcher. Vérifiez à la main que vous retrouvez bien le texte d'origine.\n",
    "\n",
    "Maintenant, essayons de voir combien de place on a gagné. Partons du principe qu'un caractère et un entier valent 1 (un octet). Vous povuez vérifier le type d'une variable avec [`isinstance`](https://docs.python.org/3/library/functions.html#isinstance) (dans cette doc, `classinfo` désigne juste le nom du type). Vous pouvez aussi utiliser la commande `type` qu'on a vue en cours, et faire la comparaison vous-même."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def taille(liste_LZ):\n",
    "    taille = 0\n",
    "    for #À COMPLÉTER\n",
    "            \n",
    "    return taille\n",
    "\n",
    "texte_compresse = compresse_LZ(texte_a_compresser, 100)\n",
    "\n",
    "print(f\"Taille compressée de {taille(texte_compresse)}. \"\n",
    "      f\"Taille non compressée {len(texte_a_compresser)}. \"\n",
    "      f\"Ratio de compression {taille(texte_compresse)/len(texte_a_compresser):.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On gagne un peu, mais pas tant que ça. D'ailleurs, est-ce que le codage LZ77 réduit forcément la taille&nbsp;?\n",
    "\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "Comment pourrait-on y remédier simplement&nbsp;?\n",
    "\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "Testons cette solution, et passons directement en paramètre de la fonction de compression cette information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compresse_LZ(texte_a_compresser, taille_fenetre, min_match):\n",
    "    texte_compresse = []\n",
    "\n",
    "    #À COMPLÉTER\n",
    "    \n",
    "    return texte_compresse\n",
    "\n",
    "\n",
    "texte_compresse = compresse_LZ(texte_a_compresser, 100, 2)\n",
    "print(len(texte_compresse))\n",
    "texte_compresse = compresse_LZ(texte_a_compresser, 100, 3)\n",
    "print(len(texte_compresse))\n",
    "texte_compresse = compresse_LZ(texte_a_compresser, 100, 4)\n",
    "print(len(texte_compresse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ça n'a pas l'air dêtre si intéressant, mais notre texte est très court. On va tester ça sur un texte un peu plus long, qui est dans un fichier, qu'on va simplement [lire](https://docs.python.org/3/tutorial/inputoutput.html#reading-and-writing-files) (ou alors vous faires un copier/coller depuis ce fichier, mais bon...).\n",
    "\n",
    "Et testez plusieurs valeurs pour les paramètres qui influencent le comportement de votre algorithme (et qu'on aurait du coup tendance à appeler _hyperparamètres_). Vous verrez leur impact, à la fois en terme de performances de compression et de temps d'exécution. Ça prendra un peu de temps, mais ça vaut peut-être le coup..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Le_Malade_imaginaire_Texte_entier.txt\", 'r', encoding='iso-8859-1') as fichier:\n",
    "    texte_a_compresser = fichier.read()\n",
    "    \n",
    "texte_compresse = compresse_LZ(texte_a_compresser, 10000, 2)\n",
    "print(f\"Taille 2, Ratio de compression {taille(texte_compresse)/len(texte_a_compresser):.2f}%.\")\n",
    "texte_compresse = compresse_LZ(texte_a_compresser, 10000, 3)\n",
    "print(f\"Taille 3, Ratio de compression {taille(texte_compresse)/len(texte_a_compresser):.2f}%.\")\n",
    "texte_compresse = compresse_LZ(texte_a_compresser, 10000, 4)\n",
    "print(f\"Taille 4, Ratio de compression {taille(texte_compresse)/len(texte_a_compresser):.2f}%.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Là ça commence à devenir performant. Et ça montre que ces hyperparamètres sont importants...\n",
    "\n",
    "Bien, on est capable de compresser des données, maintenant, reste à les décompresser&nbsp;! Là, rien de compliqué. Il faut juste parcourir la structure contenant les données compressées, et gérer le cas d'un caractère seul ou le cas d'un match. Attention tout de même, la fonction <code class=\"language-python\"></span><span class=\"ͼz\">append</span></code> n'ajoute qu'un élément à la fois. Dans le cas d'un caractère seul, ça nous suffit. Mais si on veut ajouter plusieurs éléments, c'est plus subtil. Il existe une fonction qui le fait (<code class=\"language-python\"></span><span class=\"ͼz\">extend</span></code>), mais on ne peut pas l'utiliser ici, car elle ne sait pas faire de _copie auto-référentielle_, c'est-à-dire qu'elle ne sait pas copier une partie d'une liste dans une autre en garantissant que le résultat est correct (en gros, le fait d'insérer des valeurs dans la liste bouleverse les indices que la fonction utilise en interne). Pour éviter tout problème, on va ajouter les caractères du match un par un. Et comme la distance est entre la position courante et la position de ce qu'on recopie, il suffit de compter la distance _depuis la fin du tableau_, puisque la position courante est justement la fin de ce texte. Il faudra donc utiliser un indice négatifs. Là, on va utiliser une astuce&nbsp;: à chaque fois qu'on ajoute un élément dans notre texte, on décale la fin du texte de 1. Donc, on n'a plus besoin de décaler notre indice négatif, puisque c'est la fin elle-même qui est décalée&nbsp;:\n",
    "\n",
    "<img style=\"width:75%;margin-left: auto;margin-right: auto;\" src=\"data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20width%3D%221224%22%20height%3D%22540%22%20overflow%3D%22hidden%22%20xmlns%3Av%3D%22https%3A%2F%2Fvecta.io%2Fnano%22%3E%3Cstyle%3E%3C!%5BCDATA%5B.B%7Bfont-size%3A24px%7D.C%7Bfont-family%3AConsolas%2CConsolas_MSFontService%2Csans-serif%7D.D%7Bfill%3A%234472c4%7D.E%7Bfill%3A%23a6a6a6%7D.F%7Bfont-family%3ACalibri%2CCalibri_MSFontService%2Csans-serif%7D.G%7Bstroke-width%3A1.333%7D.H%7Bstroke-miterlimit%3A8%7D.I%7Bstroke-width%3A2.667%7D.J%7Bfill-rule%3Aevenodd%7D%5D%5D%3E%3C%2Fstyle%3E%3Cdefs%3E%3CclipPath%20id%3D%22A%22%3E%3Cpath%20d%3D%22M36%20114h1224v540H36z%22%2F%3E%3C%2FclipPath%3E%3ClinearGradient%20x1%3D%22714%22%20y1%3D%22326.5%22%20x2%3D%221022%22%20y2%3D%22326.5%22%20gradientUnits%3D%22userSpaceOnUse%22%20spreadMethod%3D%22reflect%22%20id%3D%22B%22%3E%3Cstop%20offset%3D%220%22%20stop-color%3D%22%23f6f8fc%22%20stop-opacity%3D%220%22%2F%3E%3Cstop%20offset%3D%22.16%22%20stop-color%3D%22%23fff%22%2F%3E%3Cstop%20offset%3D%22.9%22%20stop-color%3D%22%23fff%22%2F%3E%3Cstop%20offset%3D%221%22%20stop-color%3D%22%23fff%22%20stop-opacity%3D%220%22%2F%3E%3C%2FlinearGradient%3E%3ClinearGradient%20x1%3D%22786%22%20y1%3D%22624.5%22%20x2%3D%221094%22%20y2%3D%22624.5%22%20gradientUnits%3D%22userSpaceOnUse%22%20spreadMethod%3D%22reflect%22%20id%3D%22C%22%3E%3Cstop%20offset%3D%220%22%20stop-color%3D%22%23f6f8fc%22%20stop-opacity%3D%220%22%2F%3E%3Cstop%20offset%3D%22.16%22%20stop-color%3D%22%23fff%22%2F%3E%3Cstop%20offset%3D%22.9%22%20stop-color%3D%22%23fff%22%2F%3E%3Cstop%20offset%3D%221%22%20stop-color%3D%22%23fff%22%20stop-opacity%3D%220%22%2F%3E%3C%2FlinearGradient%3E%3C%2Fdefs%3E%3Cg%20clip-path%3D%22url(%23A)%22%20transform%3D%22translate(-36%20-114)%22%3E%3Cg%20stroke%3D%22%23000%22%20stroke-linejoin%3D%22round%22%20stroke-miterlimit%3D%2210%22%20fill%3D%22none%22%20class%3D%22G%22%3E%3Cpath%20d%3D%22M404.201%20228.085v40.267m71.111-40.267v40.267m71.111-40.267v40.267m71.111-40.267v40.267m71.111-40.267v40.267m71.111-40.267v40.267m71.111-40.267v40.267m71.111-40.267v40.267m71.111-40.267v40.267m71.111-40.267v40.267m71.11-40.267v40.267m-782.221-40.267v40.267m853.331-40.267v40.267%22%2F%3E%3Cpath%20d%3D%22M332.423%20228.752h854.667m-854.667%2038.933h854.667M404.259%20525.86v40.267m71.17-40.267v40.267m71.17-40.267v40.267m71.17-40.267v40.267m71.17-40.267v40.267m71.17-40.267v40.267m71.17-40.267v40.267m71.169-40.267v40.267m71.17-40.267v40.267m71.172-40.267v40.267m71.17-40.267v40.267m71.17-40.267v40.267M333.089%20525.86v40.267M1258.3%20525.86v40.267%22%2F%3E%3Cpath%20d%3D%22M332.423%20526.527h926.537M332.423%20565.46h926.537%22%2F%3E%3C%2Fg%3E%3Cg%20class%3D%22H%22%3E%3Cpath%20d%3D%22M546.5%20208.5c0-4.694%204.676-8.5%2010.444-8.5h121.112c5.768%200%2010.444-3.806%2010.444-8.5%200%204.694%204.676%208.5%2010.444%208.5h121.112c5.768%200%2010.444%203.806%2010.444%208.5%22%20stroke%3D%22%234472c4%22%20fill%3D%22none%22%20class%3D%22I%22%2F%3E%3Cg%20class%3D%22D%20G%20J%22%3E%3Cpath%20d%3D%22M1125.5%20191h12.75v-19.5h25.5V191h12.75l-25.5%2019.5z%22%20stroke%3D%22%23172c51%22%2F%3E%3C%2Fg%3E%3C%2Fg%3E%3Cpath%20d%3D%22M582.935%20278.557l3.941%203.539%204.453%203.448%204.908%203.323%205.347%203.2%205.772%203.079%206.192%202.965%2013.519%205.56%2014.992%205.098%2016.331%204.636%2017.549%204.176%2018.646%203.718%2019.622%203.261%2020.474%202.805%2021.206%202.351%2021.814%201.896%2022.299%201.442%2022.661.988%2022.902.536%2023.019.083%2023.013-.37%2022.884-.821%2022.633-1.274%2022.259-1.725%2021.761-2.176%2021.141-2.627%2020.399-3.079%2019.534-3.53%2018.547-3.983%2017.439-4.435%2016.209-4.889%2014.859-5.344%2013.374-5.798%206.116-3.082%205.693-3.194%205.265-3.313%204.823-3.434%204.363-3.557%201.932-1.829-1.834-1.937-1.895%201.795.073-.065-4.291%203.499.069-.053-4.756%203.387.063-.042-5.204%203.275.058-.035-5.637%203.164.053-.028-6.055%203.052.07-.033-13.3%205.766.079-.031-14.785%205.318.066-.022-16.148%204.871.056-.016-17.386%204.422.049-.011-18.502%203.971.042-.008-19.494%203.522.038-.006-20.363%203.074.035-.005-21.109%202.624.032-.004-21.73%202.173.029-.003-22.229%201.722.028-.002-22.605%201.272.027-.002-22.858.821.026-.001-22.986.369h.026l-22.993-.083h.026l-22.875-.535h.026l-22.634-.987.028.001-22.271-1.44.03.002-21.783-1.893.032.003-21.173-2.347.034.004-20.439-2.8.038.006-19.581-3.254.042.007-18.601-3.709.048.01-17.497-4.164.055.015-16.27-4.619.065.02-14.92-5.074.078.029-13.446-5.53.069.031-6.132-2.936.052.026-5.717-3.05.057.032-5.287-3.164.063.04-4.842-3.278.069.05-4.381-3.392.075.062-3.905-3.506zm565.653%205.939l3.242-11.084-11.243%202.634a1.33%201.33%200%200%200%20.608%202.596l9.018-2.111-1.583-1.674-2.601%208.889c-.207.707.199%201.448.906%201.655s1.447-.199%201.654-.905z%22%20class%3D%22D%22%2F%3E%3Ctext%20transform%3D%22translate(1110.36%20145)%22%20class%3D%22B%20C%22%3E(8%2C%204)%3C%2Ftext%3E%3Cg%20class%3D%22H%22%3E%3Cpath%20d%3D%22M546.5%20505.5c0-4.418%204.401-8%209.83-8h122.34c5.429%200%209.83-3.582%209.83-8%200%204.418%204.401%208%209.83%208h122.34c5.429%200%209.83%203.582%209.83%208%22%20stroke%3D%22%234472c4%22%20fill%3D%22none%22%20class%3D%22I%22%2F%3E%3Cg%20class%3D%22D%20G%20J%22%3E%3Cpath%20d%3D%22M1125.5%20488h12.75v-19.5h25.5V488h12.75l-25.5%2019.5z%22%20stroke%3D%22%23172c51%22%2F%3E%3C%2Fg%3E%3C%2Fg%3E%3Cpath%20d%3D%22M654.935%20576.332l3.941%203.539%204.453%203.448%204.908%203.323%205.347%203.2%205.772%203.079%206.192%202.965%2013.519%205.56%2014.992%205.098%2016.331%204.636%2017.549%204.176%2018.646%203.718%2019.622%203.261%2020.474%202.805%2021.206%202.351%2021.814%201.896%2022.299%201.442%2022.661.988%2022.902.536%2023.019.083%2023.013-.37%2022.884-.821%2022.633-1.274%2022.259-1.725%2021.761-2.176%2021.141-2.627%2020.399-3.079%2019.534-3.53%2018.547-3.983%2017.439-4.435%2016.209-4.889%2014.859-5.344%2013.374-5.798%206.116-3.082%205.693-3.194%205.265-3.313%204.823-3.434%204.363-3.557%201.932-1.829-1.834-1.937-1.895%201.795.073-.065-4.291%203.499.069-.053-4.756%203.387.063-.042-5.204%203.275.058-.035-5.637%203.164.053-.028-6.055%203.052.07-.033-13.3%205.766.079-.031-14.785%205.318.066-.022-16.148%204.871.056-.016-17.386%204.422.049-.011-18.502%203.971.042-.008-19.494%203.522.038-.006-20.363%203.074.035-.005-21.109%202.624.032-.004-21.73%202.173.029-.003-22.229%201.722.028-.002-22.605%201.272.027-.002-22.858.821.026-.001-22.986.369h.026l-22.993-.083h.026l-22.875-.535h.026l-22.634-.987.028.001-22.271-1.44.03.002-21.783-1.893.032.003-21.173-2.347.034.004-20.439-2.8.038.006-19.581-3.254.042.007-18.601-3.709.048.01-17.497-4.164.055.015-16.27-4.619.065.02-14.92-5.074.078.029-13.446-5.53.069.031-6.132-2.936.052.026-5.717-3.05.057.032-5.287-3.164.063.04-4.842-3.278.069.05-4.381-3.392.075.062-3.905-3.506zm565.653%205.939l3.242-11.084-11.243%202.634a1.33%201.33%200%201%200%20.608%202.596l9.018-2.111-1.583-1.674-2.601%208.889c-.207.707.199%201.448.906%201.655s1.447-.199%201.654-.905z%22%20class%3D%22D%22%2F%3E%3Ctext%20transform%3D%22translate(1110.36%20442)%22%20class%3D%22B%20C%22%3E(8%2C%204)%3C%2Ftext%3E%3Cpath%20fill%3D%22url(%23B)%22%20d%3D%22M714%20307h308v39H714z%22%2F%3E%3Ctext%20transform%3D%22translate(762.493%20335)%22%20class%3D%22B%20C%22%3Etexte%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(828.326%20335)%22%20class%3D%22B%20C%20E%22%3E%5B%3C%2Ftext%3E%3Ctext%20fill%3D%22%237030a0%22%20transform%3D%22translate(841.493%20335)%22%20class%3D%22B%20C%22%3E-%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(854.66%20335)%22%20class%3D%22B%20C%22%3Edistance%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(959.993%20335)%22%20class%3D%22B%20C%20E%22%3E%5D%3C%2Ftext%3E%3Cpath%20fill%3D%22url(%23C)%22%20d%3D%22M786%20605h308v39H786z%22%2F%3E%3Ctext%20transform%3D%22translate(834.493%20633)%22%20class%3D%22B%20C%22%3Etexte%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(900.326%20633)%22%20class%3D%22B%20C%20E%22%3E%5B%3C%2Ftext%3E%3Ctext%20fill%3D%22%237030a0%22%20transform%3D%22translate(913.493%20633)%22%20class%3D%22B%20C%22%3E-%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(926.659%20633)%22%20class%3D%22B%20C%22%3Edistance%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(1031.99%20633)%22%20class%3D%22B%20C%20E%22%3E%5D%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(51.406%20256)%22%20class%3D%22B%20F%22%3ECopie%20%C3%A9l%C3%A9ment%201%20du%20match%20%3A%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(51.406%20553)%22%20class%3D%22B%20F%22%3ECopie%20%C3%A9l%C3%A9ment%202%20du%20match%20%3A%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(657.043%20178)%22%20class%3D%22B%20F%22%3Ematch%3C%2Ftext%3E%3Ctext%20transform%3D%22translate(657.043%20477)%22%20class%3D%22B%20F%22%3Ematch%3C%2Ftext%3E%3C%2Fg%3E%3C%2Fsvg%3E\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decompresse_LZ(texte_compresse):\n",
    "    \"\"\"\n",
    "    Reconstruit le texte original à partir du texte compressé LZ77\n",
    "    \"\"\"\n",
    "    texte_decompresse = []\n",
    "    i = 0\n",
    "    while i < len(texte_compresse):\n",
    "        element = texte_compresse[i]\n",
    "\n",
    "        # Cas où l'élément est un tuple (distance, longueur)\n",
    "        if #À COMPLÉTER\n",
    "        # Cas où l'élément est un caractère seul\n",
    "        else:\n",
    "            #À COMPLÉTER\n",
    "    return ''.join(texte_decompresse)\n",
    "\n",
    "texte_a_compresser = \"Voici le texte à compresser. J'espère qu'il y aura beaucoup de texte qu'on arrivera à compresser.\"\n",
    "texte_compresse = compresse_LZ(texte_a_compresser, 100, 2)\n",
    "texte_decompresse = decompresse_LZ(texte_compresse)\n",
    "print(texte_a_compresser == texte_decompresse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a un algorithme dérivé de LZSS qui fonctionne&nbsp;! Mais plutôt que de calculer manuellement la place que ça prendrait dans un fichier, comme on avait fait pour Huffman, cette fois, on va vraiment implémenter l'écriture dans le fichier. On va donc trouver un codage binaire de notre code LZSS simplifié.\n",
    "\n",
    "La structure de données compressée est une liste mixte, avec soit des caractères, soit des tuples (pour les matchs). Pour la convertir en binaire, il faut :\n",
    " * encoder les caractères simples : On va utiliser un encodage standard, ASCII étendu (c'est plus simple). Attention donc à ne pas faire tourner votre code sur du texte encodé en UTF8.\n",
    " * encoder les tuples (distance, longueur) : Pour ça, il faudra définir un format binaire pour stocker les deux valeurs : Pour la distance, on va prendre 2 octets, et 1 octet pour la longueur.\n",
    " * Très important, il faut ajouter un marqueur pour distinguer les caractères des tuples dans le flux binaire. On va prendre un bit à 0 pour le caractère seul, et un bit à 1 pour le tuple.\n",
    "\n",
    "Ça nous donne donc&nbsp;:\n",
    " * Caractère : 1 octet pour le marqueur 0 suivi de 1 octet pour le caractère.\n",
    " * Tuple (distance, longueur) : 1 octet pour le marqueur 1 suivi de 2 octets pour la distance et 1 octet pour la longueur.\n",
    "\n",
    "Une question&nbsp;: avec 2 octets pour la longueur, quelle est la taille maximale de notre taille de fenêtre&nbsp;? Et celle d'un match&nbsp;?\n",
    "\n",
    "<em>À COMPLÉTER</em>\n",
    "\n",
    "Et pour écrire vos données en binaire, on va réutiliser le type `bitarray` qu'on utilisait avec Huffman. Il suffit donc de convertir nos données en bits en utilisant la bonne taille&nbsp;:\n",
    " * Pour un littéral et pour une longueur, `f'{valeur:08b}'`\n",
    " * Pour une distance, `f\"{valeur:016b}\"`\n",
    "Et pour comparer, vous pouvez le faire avec les valeurs entières 0 et 1.\n",
    "\n",
    "Juste un petit détail&nbsp;: si on veut convertir un caractère en binaire, il faut d'abord le convertir en son code ASCII. `ord(caractere)` fait cette opération.\n",
    "\n",
    "Donc, ce qu'il faut faire, c'est&nbsp;:\n",
    " * Créer un tableau de données binaires vides (avec `bitarray()`)\n",
    " * Parcourir vos données\n",
    " * Pour chaque donnée :\n",
    "     * Si cette donnée est un littéral, l'ajouter aux données binaires, précédé de son marqueur\n",
    "     * Si cette donnée est un match, ajouter la distance puis la longueur, précédées de leur marqueur\n",
    "\n",
    "Exemple d'encodage\n",
    "* 'A' → Marqueur : 0, Code ASCII : 01000001\n",
    "    Résultat final : 001000001\n",
    "* (15, 3) → Marqueur : 1, Distance : 0000000000001111, Longueur : 00000011\n",
    "    Résultat final : 1000000000000111100000011\n",
    "\n",
    "Créez une fonction `encode_lz77` qui va prendre en entrée notre structure compressée, et générer les données binaires correspondantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_LZ(texte_compresse):\n",
    "    binaire = bitarray()\n",
    "    \n",
    "    for item in texte_compresse:\n",
    "        # Match\n",
    "        #À COMPLÉTER\n",
    "        # Littéral\n",
    "        #À COMPLÉTER\n",
    "        \n",
    "    return binaire\n",
    "\n",
    "\n",
    "texte_a_compresser = \"Voici le texte à compresser. J'espère qu'il y aura beaucoup de texte qu'on arrivera à compresser.\"\n",
    "texte_compresse = compresse_LZ(texte_a_compresser, 100, 2)\n",
    "binaire = encode_LZ(texte_compresse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, maintenant, il faut implémenter le décodage binaire. C'est à peu près le même principe, en parcourant le tableau de bits (rappelez-vous que vous pouvez donc faire du slicing dessus) et en lisant les données à décoder.\n",
    "\n",
    "Pour le décodage, voici comment convertir des données binaires stockées dans la variable `char_bits`&nbsp;:\n",
    " * Pour récupérer un caractère&nbsp;: `chr(int(char_bits.to01(), 2))`\n",
    " * Pour récupérer un entier&nbsp;: `int(taille_bits.to01(), 2)`\n",
    "\n",
    "Par contre, à vous de mettre les bonnes données dans `char_bits`.\n",
    "\n",
    "Attention tout de même, quand vous allez parcourir votre tableau binaire, il faudra veiller à avancer du bon nombre d'octets à chaque itération (puisque ça dépend de ce que vous être en train de lire, caractère ou match)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_LZ(binaire):\n",
    "    texte = []\n",
    "    i = 0\n",
    "    \n",
    "    while i < len(binaire):\n",
    "        marqueur = binaire[i]\n",
    "        i += 1  # On avance d'un bit après avoir lu le marqueur\n",
    "\t\t\n",
    "        # Littéral\n",
    "        #À COMPLÉTER\n",
    "\t\t# Match\n",
    "        else:\n",
    "            #À COMPLÉTER\n",
    "    \n",
    "    return texte\n",
    "\n",
    "\n",
    "texte_decompresse = decompresse_LZ(decode_LZ(binaire))\n",
    "print(texte_decompresse == texte_a_compresser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, il ne nous reste plus qu'à gérer les accès aux fichiers. Et on fera tourner tout ça directement sur le gros texte pour voir ce que ça donne. \n",
    "\n",
    "Là, le code vous est donné directement, car il y a une petite subtilité&nbsp;: l'écriture dans un fichier se fait forcément octet par octet. Si notre code binaire n'est pas un multiple de 8, il y aura du _padding_, c'est-à-dire que des 0 vont être ajoutés à la fin du fichier. Si on n'en tient pas compte lors du décodage, on va récupérer un texte dont la toute fin sera un peu différente. Pour éviter ça, on va stocker en en-tête de fichier la taille du padding, sur 3 bits (puisque le padding à 1 octet d'un code de taille non multiple de 8 fait au plus 7 bits, et que la valeur 7 est représentée sur 3 bits). Lors du décodage, il suffira de retirer à la foid le padding et l'en-tête, et on retrouve l'intégralité de notre code binaire d'origine, qu'il ne restera plus qu'à décompresser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitarray.util import int2ba, ba2int\n",
    "\n",
    "def sauver_LZ(texte, nom_fichier, taille_fenetre, min_match):\n",
    "    texte_compresse = compresse_LZ(texte, taille_fenetre, min_match)\n",
    "    binaire = encode_LZ(texte_compresse)\n",
    "    \n",
    "    # Calculer le padding nécessaire en tenant compte  des 3 bit\n",
    "    # d'en-tête qu'on ajoutera justement pour stocker cette valeur\n",
    "    padding_size = (8 - ((len(binaire) + 3) % 8)) % 8\n",
    "    \n",
    "    # Créer un en-tête de 3 bits pour stocker la taille du padding\n",
    "    header = bitarray(int2ba(padding_size, length=3))\n",
    "    \n",
    "    # Ajouter le padding à binaire\n",
    "    binaire.extend([0] * padding_size)\n",
    "    \n",
    "    with open(nom_fichier, 'wb') as file:\n",
    "        # Écrire l'en-tête et les données\n",
    "        file.write((header + binaire).tobytes())\n",
    "\n",
    "def charger_LZ(nom_fichier):\n",
    "    with open(nom_fichier, 'rb') as fichier:\n",
    "        contenu = fichier.read()\n",
    "        binaire = bitarray()\n",
    "        binaire.frombytes(contenu)\n",
    "        \n",
    "        # Lire l'en-tête (3 premiers bits)\n",
    "        padding_size = ba2int(binaire[:3])\n",
    "        \n",
    "        # Supprimer l'en-tête et le padding\n",
    "        if padding_size > 0:\n",
    "                  \n",
    "            binaire = binaire[3:]\n",
    "            binaire =binaire[:-padding_size] \n",
    "            # binaire = binaire[3:-padding_size]\n",
    "        else:\n",
    "            binaire = binaire[3:]\n",
    "    \n",
    "    texte_compresse = decode_LZ(binaire)\n",
    "    return decompresse_LZ(texte_compresse)\n",
    "    \n",
    "# Notez qu'on considère que le fichier est encodé en ASCII étendu, codage d'Europe occidentale\n",
    "with open(\"Le_Malade_imaginaire_Texte_entier.txt\", 'r', encoding='iso-8859-1') as fichier:\n",
    "    texte_a_compresser = fichier.read()\n",
    "sauver_LZ(texte_a_compresser, \"Le_Malade_imaginaire_Texte_entier.lz\", 10000, 3)\n",
    "\n",
    "texte = charger_LZ(\"Le_Malade_imaginaire_Texte_entier.lz\")\n",
    "print(texte == texte_a_compresser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "C'est nettement plus efficace que Huffman&nbsp;!! C'est assez normal, dans un très grand texte les taux de présence des différentes lettres varient suffisamment pour que Huffman permette de gagner de la place, mais pas assez pour battre LZSS, qui est taillé pour du texte rédigé en langue humaine. Par contre, si on adaptait Huffman pour qu'il arrive à manipuler des données non ASCII (c'est l'affaire de quelques minutes), vous pouvez être sûrs qu'il battrait sans problème LZSS sur des données binaires comme des images."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "6f118f2210741b69cbc7210d3ec59cb8c99e7985adfe2966f851dec94eec13ea"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
